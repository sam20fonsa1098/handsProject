{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import pairwise\n",
    "import pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = None\n",
    "\n",
    "accumulated_weight = 0.5\n",
    "\n",
    "roi_top    = 0\n",
    "roi_bottom = 480\n",
    "roi_right  = 200\n",
    "roi_left   = 640\n",
    "\n",
    "hand_hist = None\n",
    "traverse_point = []\n",
    "total_rectangle = 9\n",
    "hand_rect_one_x = None\n",
    "hand_rect_one_y = None\n",
    "\n",
    "hand_rect_two_x = None\n",
    "hand_rect_two_y = None\n",
    "mouseXmax       = 2725\n",
    "mouseYmax       = 765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accum_avg(frame,accumulated_weight):\n",
    "    \n",
    "    global background\n",
    "    \n",
    "    if background is None:\n",
    "        background = frame.copy().astype('float')\n",
    "        return None\n",
    "    \n",
    "    cv2.accumulateWeighted(frame,background,accumulated_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(frame,threshold_min=25):\n",
    "    \n",
    "    diff = cv2.absdiff(background.astype('uint8'),frame)\n",
    "    \n",
    "    ret,thresholded = cv2.threshold(diff,threshold_min,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    image,contours,hierarchy = cv2.findContours(thresholded.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        # ASSUMING THE LARGEST EXTERNAL CONTOUR IN ROI, IS THE HAND\n",
    "        hand_segment = max(contours,key=cv2.contourArea)\n",
    "        \n",
    "        return (thresholded,hand_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contours(hist_mask_image):\n",
    "    gray_hist_mask_image = cv2.cvtColor(hist_mask_image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray_hist_mask_image, 0, 255, 0)\n",
    "    _, cont, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rect(frame):\n",
    "    rows, cols, _ = frame.shape\n",
    "    global total_rectangle, hand_rect_one_x, hand_rect_one_y, hand_rect_two_x, hand_rect_two_y\n",
    "\n",
    "    hand_rect_one_x = np.array(\n",
    "        [6 * rows / 20, 6 * rows / 20, 6 * rows / 20, 9 * rows / 20, 9 * rows / 20, 9 * rows / 20, 12 * rows / 20,\n",
    "         12 * rows / 20, 12 * rows / 20], dtype=np.uint32)\n",
    "\n",
    "    hand_rect_one_y = np.array(\n",
    "        [9 * cols / 20, 10 * cols / 20, 11 * cols / 20, 9 * cols / 20, 10 * cols / 20, 11 * cols / 20, 9 * cols / 20,\n",
    "         10 * cols / 20, 11 * cols / 20], dtype=np.uint32)\n",
    "\n",
    "    hand_rect_two_x = hand_rect_one_x + 10\n",
    "    hand_rect_two_y = hand_rect_one_y + 10\n",
    "\n",
    "    for i in range(total_rectangle):\n",
    "        cv2.rectangle(frame, (hand_rect_one_y[i], hand_rect_one_x[i]),\n",
    "                      (hand_rect_two_y[i], hand_rect_two_x[i]),\n",
    "                      (0, 255, 0), 1)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hand_histogram(frame):\n",
    "    global hand_rect_one_x, hand_rect_one_y\n",
    "\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    roi = np.zeros([90, 10, 3], dtype=hsv_frame.dtype)\n",
    "\n",
    "    for i in range(total_rectangle):\n",
    "        roi[i * 10: i * 10 + 10, 0: 10] = hsv_frame[hand_rect_one_x[i]:hand_rect_one_x[i] + 10,\n",
    "                                          hand_rect_one_y[i]:hand_rect_one_y[i] + 10]\n",
    "\n",
    "    hand_hist = cv2.calcHist([roi], [0, 1], None, [180, 256], [0, 180, 0, 256])\n",
    "    return cv2.normalize(hand_hist, hand_hist, 0, 255, cv2.NORM_MINMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_masking(frame, hist):\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    dst = cv2.calcBackProject([hsv], [0, 1], hist, [0, 180, 0, 256], 1)\n",
    "\n",
    "    disc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (31, 31))\n",
    "    cv2.filter2D(dst, -1, disc, dst)\n",
    "\n",
    "    ret, thresh = cv2.threshold(dst, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    thresh = cv2.merge((thresh, thresh, thresh))\n",
    "\n",
    "    return cv2.bitwise_and(frame, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid(max_contour):\n",
    "    moment = cv2.moments(max_contour)\n",
    "    if moment['m00'] != 0:\n",
    "        cx = int(moment['m10'] / moment['m00'])\n",
    "        cy = int(moment['m01'] / moment['m00'])\n",
    "        return cx, cy\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def farthest_point(defects, contour, centroid):\n",
    "    if defects is not None and centroid is not None:\n",
    "        s = defects[:, 0][:, 0]\n",
    "        cx, cy = centroid\n",
    "\n",
    "        x = np.array(contour[s][:, 0][:, 0], dtype=np.float)\n",
    "        y = np.array(contour[s][:, 0][:, 1], dtype=np.float)\n",
    "\n",
    "        xp = cv2.pow(cv2.subtract(x, cx), 2)\n",
    "        yp = cv2.pow(cv2.subtract(y, cy), 2)\n",
    "        dist = cv2.sqrt(cv2.add(xp, yp))\n",
    "\n",
    "        dist_max_i = np.argmax(dist)\n",
    "\n",
    "        if dist_max_i < len(s):\n",
    "            farthest_defect = s[dist_max_i]\n",
    "            farthest_point = tuple(contour[farthest_defect][0])\n",
    "            return farthest_point\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manage_image_opr(frame, hand_hist):\n",
    "    hist_mask_image = hist_masking(frame, hand_hist)\n",
    "\n",
    "    hist_mask_image = cv2.erode(hist_mask_image, None, iterations=2)\n",
    "    hist_mask_image = cv2.dilate(hist_mask_image, None, iterations=2)\n",
    "\n",
    "    contour_list = contours(hist_mask_image)\n",
    "    max_cont = max(contour_list, key=cv2.contourArea)\n",
    "\n",
    "    cnt_centroid = centroid(max_cont)\n",
    "    cv2.circle(frame, cnt_centroid, 5, [0, 0, 255], -1)\n",
    "\n",
    "    if max_cont is not None:\n",
    "        hull = cv2.convexHull(max_cont, returnPoints=False)\n",
    "        defects = cv2.convexityDefects(max_cont, hull)\n",
    "        far_point = farthest_point(defects, max_cont, cnt_centroid)\n",
    "        cv2.line(frame, cnt_centroid, far_point, [0, 0, 255], 4)\n",
    "        dist = (cnt_centroid[0] - far_point[0]) ** 2 + (cnt_centroid[1] - far_point[1]) ** 2\n",
    "        cv2.circle(frame, cnt_centroid,  int(dist ** 0.5), (0, 0, 255), 2)\n",
    "        if len(traverse_point) < 20:\n",
    "            traverse_point.append(far_point)\n",
    "        else:\n",
    "            traverse_point.pop(0)\n",
    "            traverse_point.append(far_point)\n",
    "\n",
    "        return cnt_centroid, far_point, int(dist ** 0.5) + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canSaveOnData(event,x,y,flags,param):\n",
    "    global canSave, numbers\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        canSave = True\n",
    "        numbers = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"hand40epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_hand_hist_created = False\n",
    "num_frames = 0\n",
    "labels  = [\"FiveFingers\", \"FourFingers\", \"ThreeFingers\", \"TwoFingers\", \"OneFinger\", \"Closed\", \"Rock\", \"Nice\", \"NanoNano\", \"HangLoose\"]\n",
    "center, final  = (0, 0), (0, 0)\n",
    "canAudio       = True\n",
    "canChangeView  = True\n",
    "canChangeArea  = True\n",
    "newView        = True\n",
    "canMoveView    = True\n",
    "canMoveOneView = True\n",
    "canZoom        = True\n",
    "pastCenter     = (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('Tracking')\n",
    "cv2.setMouseCallback('Tracking', canSaveOnData) \n",
    "cam = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cam.read()    \n",
    "    frame_copy = frame.copy()\n",
    "    roi = frame[roi_top:roi_bottom,roi_right:roi_left]\n",
    "    gray = cv2.cvtColor(roi,cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray,(7,7),0)\n",
    "    \n",
    "    if num_frames < 60:\n",
    "        calc_accum_avg(gray,accumulated_weight)\n",
    "        \n",
    "        if num_frames <= 59:\n",
    "            cv2.putText(frame_copy,'WAIT. GETTING BACKGROUND',(200,300),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)\n",
    "            cv2.imshow('Finger Count',frame_copy)\n",
    "    else:\n",
    "        \n",
    "        hand = segment(gray)\n",
    "        \n",
    "        if hand is not None:\n",
    "            thresholded , hand_segment = hand\n",
    "            if k == ord('z'):\n",
    "                is_hand_hist_created = True\n",
    "                hand_hist = hand_histogram(roi)\n",
    "            if is_hand_hist_created:\n",
    "                try:\n",
    "                    center, final, radius = manage_image_opr(roi, hand_hist)\n",
    "                    p1 = (center[0] - radius, center[1] + radius)\n",
    "                    p2 = (center[0] + radius, center[1] - radius)\n",
    "                    thresholded = thresholded[p2[1]: p1[1], p1[0]: p2[0]]\n",
    "                    \n",
    "                    img = thresholded / 255\n",
    "                    img = cv2.resize(img, (100, 100))\n",
    "                    img = np.array([img])\n",
    "                    img = img.reshape(1, 100, 100, 1)\n",
    "                    \n",
    "                    prediction = model.predict_classes(img)\n",
    "                    if(labels[prediction[0]] == \"FiveFingers\"):\n",
    "                        pyautogui.moveTo(mouseXmax - 2 * center[0] * mouseXmax / roi_left, -400 + 2 * center[1] *  mouseYmax / roi_bottom)\n",
    "                        if (not canClick):\n",
    "                            canClick = True\n",
    "                        if (not canAudio):\n",
    "                            canAudio = True\n",
    "                        if (not newView):\n",
    "                            newView  = True\n",
    "                    elif(labels[prediction[0]] == \"Closed\" and canClick):\n",
    "                        canClick = False\n",
    "                        pyautogui.click(pyautogui.position())\n",
    "                        if (not canChangeView):\n",
    "                            pyautogui.keyUp('ctrl')\n",
    "                            canChangeView = True\n",
    "                        if (not canMoveView):\n",
    "                            canMoveView = True\n",
    "                        if (not canMoveOneView):\n",
    "                            canMoveOneView = True\n",
    "                    elif(labels[prediction[0]] == \"HangLoose\"):\n",
    "                        if (canAudio):\n",
    "                            pyautogui.hotkey('ctrl', 'f9')\n",
    "                            canAudio = False\n",
    "                    elif(labels[prediction[0]] == \"Rock\" and pastCenter != (0, 0)):\n",
    "                        if (center[0] - pastCenter[0] > 4 ):\n",
    "                            pyautogui.hotkey('ctrl', 'f10')\n",
    "                        elif (-center[0] + pastCenter[0] > 4):\n",
    "                            pyautogui.hotkey('ctrl', 'f11')\n",
    "                    elif (labels[prediction[0]] == \"NanoNano\" and canChangeView):\n",
    "                        pyautogui.keyDown('ctrl')\n",
    "                        pyautogui.press('tab')\n",
    "                        canChangeView = False\n",
    "                    elif (labels[prediction[0]] == \"ThreeFingers\" and newView):\n",
    "                        pyautogui.hotkey('ctrl', 't')\n",
    "                        newView = False\n",
    "                    elif (labels[prediction[0]] == \"TwoFingers\" and canMoveView):\n",
    "                        pyautogui.hotkey('alt', 'f7')\n",
    "                        canMoveView = False\n",
    "                    elif (labels[prediction[0]] == \"Nice\" and canMoveOneView):\n",
    "                        pyautogui.hotkey('alt', 'f')\n",
    "                        canMoveOneView = False\n",
    "                    elif (labels[prediction[0]] == \"OneFinger\" and pastCenter != (0, 0)):\n",
    "                        if (center[0] - pastCenter[0] > 4 ):\n",
    "                            pyautogui.hotkey('ctrl', '-')\n",
    "                        elif (-center[0] + pastCenter[0] > 4):\n",
    "                            pyautogui.hotkey('ctrl', '+')\n",
    "                    pastCenter = center   \n",
    "                    cv2.putText(roi, labels[prediction[0]], (70, 75), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 4)\n",
    "                except:\n",
    "                    cv2.putText(roi, \"Error\", (70, 75), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 4)\n",
    "            else:\n",
    "                roi = draw_rect(roi)\n",
    "            try:\n",
    "                cv2.imshow('Thresholded',thresholded)\n",
    "                cv2.imshow(\"Tracking\", roi)\n",
    "            except:\n",
    "                center =  center\n",
    "\n",
    "            \n",
    "    cv2.rectangle(frame_copy,(roi_left,roi_top),(roi_right,roi_bottom),(0,0,255),5)\n",
    "    \n",
    "    num_frames += 1\n",
    "    \n",
    "    cv2.imshow('Finger Count',frame_copy)\n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
